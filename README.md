\## ğŸ›’ Superstore Sales Analysis



This project analyzes the \*\*Superstore Sales dataset\*\* using Python for data cleaning, visualization, and predictive modeling.



\### ğŸ“‚ Project Files

\- \*\*Superstore\_Sales\_Analysis.ipynb\*\* â€“ Jupyter Notebook with all analysis and modeling steps

\- \*\*Superstore.csv\*\* â€“ Raw dataset (CSV format)



\### ğŸ›  Technologies Used

\- pandas, numpy

\- seaborn, matplotlib

\- scikit-learn (train-test split, regression, PCA, metrics)

\- xgboost



\### ğŸ” Analysis Workflow

1\. Load and inspect the dataset

2\. Handle missing values and data cleaning

3\. Exploratory data analysis (EDA) â€“ sales by region, category, etc.

4\. Feature scaling and dimensionality reduction (StandardScaler, PCA)

5\. Predictive modeling using:

&nbsp;  - Linear Regression

&nbsp;  - Random Forest Regressor

&nbsp;  - XGBoost Regressor

6\. Model evaluation with RMSE and RÂ² metrics



\### ğŸš€ How to Run

1\. Clone this repository:

&nbsp;  ```bash

&nbsp;  git clone https://github.com/Imran013/superstore-sales-analysis.git

&nbsp;  cd superstore-sales-analysis

&nbsp;  ```

2\. Install dependencies:

&nbsp;  ```bash

&nbsp;  pip install pandas numpy seaborn matplotlib scikit-learn xgboost

&nbsp;  ```

3\. Run the Jupyter Notebook:

&nbsp;  ```bash

&nbsp;  jupyter notebook Superstore\_Sales\_Analysis.ipynb

&nbsp;  ```



\### ğŸ“Š Results

\- Visual insights on sales performance across regions and product categories

\- Predictive models to estimate sales outcomes

\- Comparison of model accuracy (Linear Regression vs. Random Forest vs. XGBoost)



